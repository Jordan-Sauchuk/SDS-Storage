{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SSD Setup.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "kDUxrB-zr-Bt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Set Up Libraries"
      ]
    },
    {
      "metadata": {
        "id": "GObaBm6Gr4r_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "9df08265-a81e-4902-92f7-0da91b7345a6"
      },
      "cell_type": "code",
      "source": [
        "#!pip uninstall PyTorch\n",
        "!pip install https://download.pytorch.org/whl/cu91/torch-0.3.1-cp36-cp36m-linux_x86_64.whl "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.3.1 from https://download.pytorch.org/whl/cu91/torch-0.3.1-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu91/torch-0.3.1-cp36-cp36m-linux_x86_64.whl (531.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 531.3MB 28kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.1) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.1) (1.14.6)\n",
            "\u001b[31mfastai 1.0.48 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.48 has requirement torch>=1.0.0, but you'll have torch 0.3.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.0.1.post2\n",
            "    Uninstalling torch-1.0.1.post2:\n",
            "      Successfully uninstalled torch-1.0.1.post2\n",
            "Successfully installed torch-0.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UF8G-1WZvfIK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Locate the files in Google Drive - You can copy the path or use the file tab on the left of this page to navigate. For example, I recently downloaded the files in a folder called Code for Mac and Linux 3. I navigated through with content > gdrive > My Drive > Colab Notebooks > Code for Mac and Linux 3"
      ]
    },
    {
      "metadata": {
        "id": "RXmHXbNEsPnv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#%cd #file path here or go through each "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I_mIKZUBtV0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3507fdce-2c06-417c-e858-e2aff40c2c18"
      },
      "cell_type": "code",
      "source": [
        "%cd gdrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-Z5Oe_OWtdCJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2bc4710-ab23-48f5-cb07-993c9f078ef6"
      },
      "cell_type": "code",
      "source": [
        "%cd My Drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X8VPBayHtlQ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35ca8ecc-7f92-4267-ba02-5b945f9aa5b9"
      },
      "cell_type": "code",
      "source": [
        "%cd Colab Notebooks"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xyUybUZftojf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "301841a9-4893-4f60-afbd-6e6a87600f24"
      },
      "cell_type": "code",
      "source": [
        "%cd Code for Mac and Linux 3"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/Code for Mac and Linux 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fVmgwXpxwDC3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Now that we are located in the right path and have PyTorch installed, we can run the file by either adding the code or using a shell command. "
      ]
    },
    {
      "metadata": {
        "id": "1DEkLbMMvTgN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#running the file\n",
        "!python object_detection_commented.py\n",
        "\n",
        "\n",
        "# the file will use the CPU version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7pNAHT4RtxP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1244
        },
        "outputId": "ceb7d8e3-85f8-40c2-a0a2-2aa269c890f1"
      },
      "cell_type": "code",
      "source": [
        "#running the file via the code and this is GPU enabled\n",
        "#Object Detection\n",
        "\n",
        "# Importing the libraries\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import cv2\n",
        "from data import BaseTransform, VOC_CLASSES as labelmap\n",
        "from ssd import build_ssd\n",
        "import imageio\n",
        "\n",
        "# Defining a function that will do the detections\n",
        "def detect(frame, net, transform): # We define a detect function that will take as inputs, a frame, a ssd neural network, and a transformation to be applied on the images, and that will return the frame with the detector rectangle.\n",
        "    height, width = frame.shape[:2] # We get the height and the width of the frame.\n",
        "    frame_t = transform(frame)[0] # We apply the transformation to our frame.\n",
        "    x = torch.from_numpy(frame_t).permute(2, 0, 1) # We convert the frame into a torch tensor.\n",
        "    x = Variable(x.unsqueeze(0)) # We add a fake dimension corresponding to the batch.\n",
        "    #added\n",
        "    x = x.cuda()\n",
        "    #\n",
        "    y = net(x) # We feed the neural network ssd with the image and we get the output y.\n",
        "    detections = y.data # We create the detections tensor contained in the output y.\n",
        "    scale = torch.Tensor([width, height, width, height]) # We create a tensor object of dimensions [width, height, width, height].\n",
        "    for i in range(detections.size(1)): # For every class:\n",
        "        j = 0 # We initialize the loop variable j that will correspond to the occurrences of the class.\n",
        "        while detections[0, i, j, 0] >= 0.6: # We take into account all the occurrences j of the class i that have a matching score larger than 0.6.\n",
        "            #pt = (detections[0, i, j, 1:] * scale).numpy() # We get the coordinates of the points at the upper left and the lower right of the detector rectangle.\n",
        "            #added\n",
        "            pt = (detections[0, i, j, 1:] * scale).cpu().numpy()\n",
        "\n",
        "            cv2.rectangle(frame, (int(pt[0]), int(pt[1])), (int(pt[2]), int(pt[3])), (255, 0, 0), 2) # We draw a rectangle around the detected object.\n",
        "            cv2.putText(frame, labelmap[i - 1], (int(pt[0]), int(pt[1])), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_AA) # We put the label of the class right above the rectangle.\n",
        "            j += 1 # We increment j to get to the next occurrence.\n",
        "    return frame # We return the original frame with the detector rectangle and the label around the detected object.\n",
        "\n",
        "###\n",
        "\n",
        "\n",
        "cuda = torch.cuda.device(0)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "else:\n",
        "\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "# Creating the SSD neural network\n",
        "net = build_ssd('test') # We create an object that is our neural network ssd.\n",
        "net.load_state_dict(torch.load('ssd300_mAP_77.43_v2.pth', map_location = lambda storage, loc: storage)) # We get the weights of the neural network from another one that is pretrained (ssd300_mAP_77.43_v2.pth).\n",
        "\n",
        "# Creating the transformation\n",
        "transform = BaseTransform(net.size, (104/256.0, 117/256.0, 123/256.0)) # We create an object of the BaseTransform class, a class that will do the required transformations so that the image can be the input of the neural network.\n",
        "\n",
        "# Doing some Object Detection on a video\n",
        "reader = imageio.get_reader('funny_dog.mp4') # We open the video.\n",
        "fps = reader.get_meta_data()['fps'] # We get the fps frequence (frames per second).\n",
        "writer = imageio.get_writer('output.mp4', fps = fps) # We create an output video with this same fps frequence.\n",
        "for i, frame in enumerate(reader): # We iterate on the frames of the output video:\n",
        "    frame = detect(frame, net.eval(), transform) # We call our detect function (defined above) to detect the object on the frame.\n",
        "    writer.append_data(frame) # We add the next frame in the output video.\n",
        "    print(i) # We print the number of the processed frame.\n",
        "writer.close() # We close the process that handles the creation of the output video.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/Code for Mac and Linux 3/ssd.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  self.softmax(conf.view(-1, self.num_classes)),  # conf preds\n",
            "WARNING:root:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1080, 1920) to (1088, 1920) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to None (risking incompatibility). You may also see a FFMPEG warning concerning speedloss due to data not being aligned.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}